% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/responses.R
\name{ModelResponse}
\alias{ModelResponse}
\title{ModelResponse R6 Class}
\description{
The \code{ModelResponse} class represents a model response object in the OpenAI API.
}
\section{Super class}{
\code{openaiapi::Utils} -> \code{ModelResponse}
}
\section{Public fields}{
\if{html}{\out{<div class="r6-fields">}}
\describe{
\item{\code{id}}{Character. Unique identifier for this Response.}

\item{\code{created_at}}{Numeric. Unix timestamp (in seconds) of when this Response was created.}

\item{\code{error}}{List or NULL. An error object returned when the model fails to generate a Response.}

\item{\code{incomplete_details}}{List or NULL. Details about why the response is incomplete.}

\item{\code{instructions}}{Character or NULL. Inserts a system (or developer) message as the first item in the model's context.}

\item{\code{max_output_tokens}}{Integer or NULL. An upper bound for the number of tokens that can be generated for a response, including visible output tokens and reasoning tokens.}

\item{\code{metadata}}{List. Set of 16 key-value pairs that can be attached to an object.}

\item{\code{model}}{Character. Model ID used to generate the response, like gpt-4o or o1.}

\item{\code{output}}{List. An array of content items generated by the model.}

\item{\code{output_text}}{Character or NULL. SDK-only convenience property that contains the aggregated text output from all output_text items in the output array, if any are present.}

\item{\code{parallel_tool_calls}}{Logical. Whether to allow the model to run tool calls in parallel.}

\item{\code{previous_response_id}}{Character or NULL. The unique ID of the previous response to the model.}

\item{\code{reasoning}}{List or NULL. Configuration options for reasoning models.}

\item{\code{status}}{Character. The status of the response generation.}

\item{\code{temperature}}{Numeric or NULL. What sampling temperature to use, between 0 and 2.}

\item{\code{text}}{List. Configuration options for a text response from the model.}

\item{\code{tool_choice}}{Character or List. How the model should select which tool (or tools) to use when generating a response.}

\item{\code{tools}}{List. An array of tools the model may call while generating a response.}

\item{\code{top_p}}{Numeric or NULL. An alternative to sampling with temperature, called nucleus sampling.}

\item{\code{truncation}}{Character or NULL. The truncation strategy to use for the model response.}

\item{\code{usage}}{List. Represents token usage details including input tokens, output tokens, a breakdown of output tokens, and the total tokens used.}

\item{\code{user}}{Character. A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse.}
}
\if{html}{\out{</div>}}
}
\section{Methods}{
\subsection{Public methods}{
\itemize{
\item \href{#method-ModelResponse-new}{\code{ModelResponse$new()}}
\item \href{#method-ModelResponse-get}{\code{ModelResponse$get()}}
\item \href{#method-ModelResponse-clone}{\code{ModelResponse$clone()}}
}
}
\if{html}{\out{
<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="openaiapi" data-topic="Utils" data-id="store_response"><a href='../../openaiapi/html/Utils.html#method-Utils-store_response'><code>openaiapi::Utils$store_response()</code></a></span></li>
</ul>
</details>
}}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-ModelResponse-new"></a>}}
\if{latex}{\out{\hypertarget{method-ModelResponse-new}{}}}
\subsection{Method \code{new()}}{
Initialize a \code{ModelResponse} object.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{ModelResponse$new(
  response_id = NULL,
  input = NULL,
  ...,
  resp = NULL,
  .async = TRUE
)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{response_id}}{Character. Unique identifier for this Response.}

\item{\code{input}}{Character or List. Text, image, or file inputs to the model, used to generate a response.}

\item{\code{...}}{Additional parameters to pass to the model.}

\item{\code{resp}}{List. The response object returned by the OpenAI API.}

\item{\code{.async}}{Logical. Whether to retrieve the response asynchronously.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-ModelResponse-get"></a>}}
\if{latex}{\out{\hypertarget{method-ModelResponse-get}{}}}
\subsection{Method \code{get()}}{
Get a fresh copy of the model response.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{ModelResponse$get()}\if{html}{\out{</div>}}
}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-ModelResponse-clone"></a>}}
\if{latex}{\out{\hypertarget{method-ModelResponse-clone}{}}}
\subsection{Method \code{clone()}}{
The objects of this class are cloneable with this method.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{ModelResponse$clone(deep = FALSE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{deep}}{Whether to make a deep clone.}
}
\if{html}{\out{</div>}}
}
}
}
